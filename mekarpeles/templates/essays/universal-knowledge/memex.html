<div class="file_body post_body">
<h1>Memex</h1>
<date>2016-07-01</date>
<p>The Memex is something which has been explored and re-imagined hundreds of times. "GLUT Mastering Information Through the Ages" is a gentle introduction to Memex over the ages. Suffice to say, many have devoted their lives to curating  great organizational works. For instance, the Syntopicon <a href="https://en.wikipedia.org/wiki/A_Syntopicon:_An_Index_to_The_Great_Ideas." data-referer-safe="1" onclick="this.href=&quot;https://slack-redir.net/link?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FA_Syntopicon%3A_An_Index_to_The_Great_Ideas.&amp;v=3&quot;" onmouseover="this.href=TS.utility.referer_safe_url_map[&quot;https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FA_Syntopicon%3A_An_Index_to_The_Great_Ideas.&quot;]" data-referer-original-href="https://en.wikipedia.org/wiki/A_Syntopicon:_An_Index_to_The_Great_Ideas." rel="noreferrer" target="https://en.wikipedia.org/wiki/A_Syntopicon:_An_Index_to_The_Great_Ideas.">https://en.wikipedia.org/wiki/A_Syntopicon:_An_Index_to_The_Great_Ideas.</a> Or Pliny's Naturalis Historiæ (https://books.archivelab.org/b/cpliniisecundin00secugoog). Or the Great Conversation (https://en.wikipedia.org/wiki/Great_Conversation). Or Wikipedia. Or Google. Each of these players focused on a very specific spaces: indexing books and literature, finding web pages. Google has a variety of portals for navigating different media; images versus web pages, or even academic papers, or videos.  </p><p></p><p>I think it's safe to say, nearly all who see the value of the idea that is the Memex want it for everything. They see a single, unified, interoperable world with universal access to information of all types, accessible at the speed of thought and connected to all relevant context. I can relate, given my life goal is to curate a living map of the world's knowledge. To create the Memex. </p><p></p><p>As it pertains to the Archive Labs, I believe it would be useful, as a first step, to have a general discussion about memex to ensure we're all talking about the same. From the comments i'm reading (said with a voice of caution, having a vested interest in the results, and not a voice of directed criticisms) each of us is strong-willed and implicitly concede little, we're working on very specific fine-brush-stroke approaches (IPFS, IIIF, Open Annotations, Matrix, Stronglink) and potentially trying to boil the ocean with our optimistic approach that all these these can and should be united into a single coherent fabric.</p><p></p><p><b>Content is Key</b> </p><p>One thing I often find myself forgetting is, the idea of a Memex is possible, is actualized because the the right <i>data </i>exists and the right <i>links</i> exist. And all this is in "some" canonical format. Most engineers are ill equiped or have little interest in providing the domain expertise (read: unscalable busy work?) to research relationships, to marshall this data into the right form, or to create such links. I often believe I can add far more value through building the right infrastructure, but I'm really ignoring the <b>actual</b> problem and focusing on another problem <b>because</b> I happen to know how to solve it at scale. Entity detection, recognitionm, and resolution, natural language processing, and<b> </b>inferring <b>meaningful</b> associations between entites is <b>non-trivial </b>even with compelling proofs of concept based on words like "CNNs" and "Deep Learning".  Anyway, these technologists (I'm talking about me here) are confident, if an easy system exists (e.g. Wikipedia) then people (scholars; the domain experts; the memex cravers) will use it. And in the case of Wikipedia, ~500[<a href="http://www.aaronsw.com/weblog/whowriteswikipedia" data-referer-safe="1" onclick="this.href=&quot;https://slack-redir.net/link?url=http%3A%2F%2Fwww.aaronsw.com%2Fweblog%2Fwhowriteswikipedia&amp;v=3&quot;" onmouseover="this.href=TS.utility.referer_safe_url_map[&quot;http%3A%2F%2Fwww.aaronsw.com%2Fweblog%2Fwhowriteswikipedia&quot;]" data-referer-original-href="http://www.aaronsw.com/weblog/whowriteswikipedia" rel="noreferrer" target="http://www.aaronsw.com/weblog/whowriteswikipedia">1</a>] people (who were some hybrid of academic, technologist, or memex enthusiast)  have made a pretty massive impact; by creating a very specific, focused sandbox which is insulated by and large from the rest of the world wide web. The thing which I believe we (the community at large) agree upon is, once such thoughtfully culled data and links/relationships exist in a canonical format, and are accessible (both in terms of API and content/rights) then anyone and everyone can and should be able to build magical (and hopefully interoperable) things. Things intent on lasting forever... On <b>top</b> the right Data and Connections.</p><p></p><p>The point is, I think a too-often overlooked part of the memex challenge -- i.e. having a complete solution -- is having access to the right data and relations.  And there's a variety of reasons. Sometimes the humanitarian/social/policy challenges seem insurmountable so we work on the technical aspects which seem addressable. Consider reading one of my favourite essays by Cory Doctrow, recommended to me by Ben Trask, entitled <a href="http://www.well.com/~doctorow/metacrap.htm" data-referer-safe="1" onclick="this.href=&quot;https://slack-redir.net/link?url=http%3A%2F%2Fwww.well.com%2F~doctorow%2Fmetacrap.htm&amp;v=3&quot;" onmouseover="this.href=TS.utility.referer_safe_url_map[&quot;http%3A%2F%2Fwww.well.com%2F~doctorow%2Fmetacrap.htm&quot;]" data-referer-original-href="http://www.well.com/~doctorow/metacrap.htm" rel="noreferrer" target="http://www.well.com/~doctorow/metacrap.htm">Metacrap</a>.</p><ul><li>It takes a long time to become an expert in a subject matter (so the expertise must come from a lot of people</li><li>There is a disconnect in communication between domain and field experts and technologists</li><li>Many of the institutions with useful data have no intention of sharing it</li><li>Many institutions which want to share their data often don't have the resources to do so</li><li>[Agreeing upon] Naming  and (thus by association metadata) is <b>hard</b>.</li><li>Building technology to (at least augment our ability to) organize things in a way which makes sense to humans is <b>tough</b> (but not insurmountable). </li></ul><p></p><p>Perhaps data can be solved at massive scale once the right infrastructure and plumbing is in place (i.e. once we have well-formed data models and have a good interface -- whether software or human facing -- which facilitates the aggregating and connecting of data)... But again, I fear this "technology" first approach to create a general framework which encompoassing everything, succumbs to hubris. It ignores the Pareto Principle, that 20% of our content provides 80% of the value. That 20% of the people provide 80% the value. And that we can do 20% of the work and get 80% of the value.</p><p></p><p>In reality, we likely shouldn't care about "everything" (all data)<i>. </i>It's expensive to store data and, at very least, there's benefit to prioritizing the most valuable (assume we have a mutual, good definition for value, which is <b>hard</b>) and easiest/cheapest to collect.  There's some discrete set of information which the average person finds important and requests often, and these works more often than not share common criteria. Content is key and spatial and temporal locality suggests the most useful content is that which is similar and has been accessed recently. In addition to subject matter, great works often share similar formatting (e.g. many works have emulated the style of Euclid's Elements, famous for the way, as much as the content, it was written). Lasting, meaningful works often entail data that individuals or machines have spent a long time thinking about, constructing, or presenting. To a degree, the investment of computation contributes to the works scarcity and value. Suffice to say, as it applies to the year 2016, I am under the impression meaningful works manifest as great texts, data sets, academic papers, code repositories, stories, concerts, artwork, largely untapped ephemeral human knowledge, architecture, etc... The ephemerality of unrecorded human knowledge (not documenting their processes, that we have no way to just "save" our brains, let along all our spoken conversations) tears at my heart, but I recognize this digression and will table it for a rainy day. The point being, by virtue of the fact that <i>common differences </i>have come into existence<i> </i>(e.g. a handful of mutually-different similar formats, globally inaccessible nomenclature yielding domain specific understandability, etc), it seems intuitive the benefits of curating each of these domains (not just media formats – like all books – but also subject matter, e.g. medicine) in isolation. And in academia, this is essentially how it works. Researchers laser focus on their specific subject area and then use a canonical format to link out to their references. This ingroup is still trying to figure out how to effectively integrate sources (like movies and figures) into their work – the best we have is essentiall a URL. Which maybe is alright...</p><p></p><p>The idea of a Memex is so fantastic because we can imagine a system on top of glorious data on a golden platter (which may not yet exist in the form we need/imagine it). With the right data we can vividly imagine  Memex-powered services which allow us to access more of it, better. </p><p></p><p>That isn't to say everyone should focus on data. There are those destined to fall into the neverending spiral of getting metadata "<a href="http://www.well.com/~doctorow/metacrap.htm" data-referer-safe="1" onclick="this.href=&quot;https://slack-redir.net/link?url=http%3A%2F%2Fwww.well.com%2F~doctorow%2Fmetacrap.htm&amp;v=3&quot;" onmouseover="this.href=TS.utility.referer_safe_url_map[&quot;http%3A%2F%2Fwww.well.com%2F~doctorow%2Fmetacrap.htm&quot;]" data-referer-original-href="http://www.well.com/~doctorow/metacrap.htm" rel="noreferrer" target="http://www.well.com/~doctorow/metacrap.htm">right</a>",  no doubt to end up one of few privileged who understand the taxonomy or the value it affords. These efforts often become deprecated because the knowledge within fails to remain relevant quickly enough and lags behind the means of using it.</p><p></p><p>Whether the strategy favors a depth-first approach (getting all the data and relations right down to its axioms for a specific format) or breadth-first (accommodating every media format and asset around a specific topic), I assert setting a scope is the difference between success and failure. That and the ability to avoid distractions and pyrrhic victories.</p><p></p><p><b>Distractions &amp; Pyrrhic Victories</b></p><p>Preservation, decentralization, security and content verification and authentication, identity. These are all nice augmentations people request once a service has proven its value. Many companies have capitalized on this notion by creating generalized white-labeled frameworks, for instance, to serve authentication. And services who realize these areas are not their core competencies use these general services (e.g. oauth or some pci compliance service like stripe) because they might recognize there are other areas where their expertise allows them to add greater value by remaining focused.</p><p></p><p>A problem I foresee in creating a "Memex" is the web is fundamentally complex and messy... And challenging to make interoperable. OpenAnnotations, IIIF, the original WebDAV spec (which people seldom refer back to), linked data and IPLD, all give us strong foundations for creating coherent maps across the web and for levering technology to augment our situation.</p><p></p><p>The reality I've seen is, many IIIF services don't list any of their assets and are hard to discover, many IIIF collections point to private/locked down, that WebDAV essentially lost to superior closed/proprietary specs like google docs (according to Jim Whitehead, the creator) and that there are tens of millions of academic papers with valuable content which can't be included in our memex.</p><p></p><p>If I were trying to solve the problem of memex, I'd focus exclusively on plaintext works within a specific domain. This is one of the reasons why I believe in #scholar as a vector of attack to create a commons of some of the world's most valuable data -- academic papers. This content has measurable value, it generally of the same form (though even normalizing academic papers is an exceedingly challenging problem – both to accomplish retroactively and to encourage fixing. moving forward). If one doesn't focus on a specific domain, one must build additional tech to coalesce all these forms of content and their mutual peculiarities into a common format or build a complex spec which does the same thing (schema.org + ipld, etc). Maybe this doesn't entail as much overhead as I make it appear.</p><p></p><p>As an anecdote,  I think sticking to the basics and focusing on "data" is what Wikipedia and Wikidata have essentially done. Today, their infrastructure leaves a lot to be desired and it prevents them from moving as quickly as they could. But then again IPFS and many other decentralized tools have novel infrastructure and have yet to hit critical mass with the "right" data. Admitedly, there's some sweet spot in between models like these (and there aren't only two models), but finding a group of dedicated people who will make meaningful progress on the "memex" requires compromise, deep mutualy respect and understanding, patience and (I'd guess) ~1 year of discussion to align and ensure mutual understanding. It starts with a collaborative drawing (which only includes non-contentious components about which everyone – or at least the ones who will do the majority of the heavy lifting –  unanymously agrees), and then focus on that goal.</p><p></p><p><b>Conclusion</b></p><p>The Memex of the year 3000 often entails a lot of great things – search across media types, fault / single-point-of-failure tolerance, distributed computation, perfect interoperability / translation / data-interchange between services, comptuation to augment our fact-checking and reproduce scientific results, permission systems, and many other desirable features. While it's slightly depressing to admit, most "schools" (groups / independent projects) of thought are fundamentally prioritizing for different things/features and bundling them into an uncontentious topic which everyone wants to see. It's a springboard to accomplishing other goals. The result is often a large community of folks attempting to  work on the same project because they believe joining forces will result in success.</p><p></p><p>I believe the group which will succeed are the ones who find the uncontentious areas on which members all agree and then work towards a specific, scoped goal. </p></div>
